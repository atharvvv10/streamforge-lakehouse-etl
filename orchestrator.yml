version: '3.9'
services:
  discovery-node:
    image: confluentinc/cp-zookeeper:7.6.1
    hostname: discovery-node
    container_name: pipeline-coordination
    ports:
      - 3181:2181
    environment:
      ZOO_CLIENT_PORT: 2181
    networks:
      - stream-lakehouse
  streaming-server:
    image: confluentinc/cp-server:7.6.1
    hostname: kafka-main-server
    container_name: primary-stream-server
    depends_on:
      - discovery-node
    ports:
      - 9092:9092
      - 30000:29092
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server localhost:29092 --list"]
      interval: 15s
      timeout: 5s
      retries: 4
    environment:
      KAFKA_BROKER_INDEX: 1
      KAFKA_CLUSTER_CONTROLLER: 'discovery-node:2181'
      KAFKA_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka-main-server:29092,EXTERNAL://localhost:9092
      KAFKA_OFFSETS_REPLICAS: 1
      KAFKA_TXN_REPLICAS: 1
      KAFKA_TXN_MIN_ISR_COUNT: 1
      KAFKA_LOG_LEVEL_EXTERNAL: INFO
      KAFKA_METRIC_ENABLE: 'false'
      KAFKA_TELEMETRY_DISABLE: 'true'
    networks:
      - stream-lakehouse
  kafka-web-ui:
    image: confluentinc/cp-enterprise-control-center:7.6.1
    hostname: monitoring-ui
    container_name: stream-monitor-dashboard
    depends_on:
      - streaming-server
    ports:
      - 8091:9021
    environment:
      CONTROL_CENTER_SERVERS: 'kafka-main-server:29092'
      CONTROL_CENTER_REPLICAS: 1
      CC_TOPIC_PARTITIONS: 1
      CC_MONITORING_PARTITIONS: 1
      CC_METRICS_REPLICATION: 1
      CC_UI_PORT: 9021
    networks:
      - stream-lakehouse
  data-generator:
    container_name: data-generator-pod
    build:
      context: ./producer
    depends_on:
      - streaming-server
    environment:
      KAFKA_BROKER_HOST: kafka-main-server:29092
    networks:
      - stream-lakehouse
  flink-job-master:
    container_name: stream-job-master
    image: flink:1.18.1-scala_2.12-java11
    ports:
      - 8084:18081
    command: jobmanager
    environment:
      FLINK_YML_CONF: |
        jobmanager.rpc.address: flink-job-master
        rest.port: 18081
        state.backend: rocksdb
        state.backend.incremental: true
      S3_BUCKET_REGION: us-east-1
      S3_AUTH_KEY_ID: user-s3
      S3_AUTH_SECRET_KEY: s3-secret-key
      S3_DEFAULT_REGION_NAME: us-east-1
      S3_CUSTOM_ENDPOINT: http://minio-store:9000
      S3_PATH_ACCESS: true
      JAVA_OPTS_AWS: -Daws.accessKeyId=user-s3 -Daws.secretKey=s3-secret-key
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:18081/overview"]
    networks:
      - stream-lakehouse
  flink-task-worker:
    container_name: stream-task-worker
    image: flink:1.18.1-scala_2.12-java11
    depends_on:
      - flink-job-master
    command: taskmanager
    environment:
      FLINK_YML_CONF: |
        jobmanager.rpc.address: flink-job-master
        rest.port: 18081
        taskmanager.numberOfTaskSlots: 4
        state.backend: rocksdb
        state.backend.incremental: true
      S3_BUCKET_REGION: us-east-1
      S3_AUTH_KEY_ID: user-s3
      S3_AUTH_SECRET_KEY: s3-secret-key
      S3_DEFAULT_REGION_NAME: us-east-1
      S3_CUSTOM_ENDPOINT: http://minio-store:9000
      S3_PATH_ACCESS: true
      JAVA_OPTS_AWS: -Daws.accessKeyId=user-s3 -Daws.secretKey=s3-secret-key
    networks:
      - stream-lakehouse
  flink-sql-job-submitter:
    container_name: flink-sql-submitter
    depends_on:
      flink-job-master:
        condition: service_healthy
      flink-task-worker:
        condition: service_started
    build:
      context: ./flink/sql-client/
    environment:
      FLINK_MASTER_HOST: flink-job-master
      MINIO_SVC_ENDPOINT: http://minio-store:9000
      MINIO_PATH_ACCESS_STYLE: true
      AWS_ACCESS_KEY: user-s3
      AWS_SECRET_KEY: s3-secret-key
      AWS_REGION_CODE: us-east-1
      AWS_DEFAULT_REGION: us-east-1
      JAVA_OPTS_ENV: -Daws.accessKeyId=user-s3 -Daws.secretKey=s3-secret-key
    volumes:
      - type: bind
        source: ${PWD}/flink/sql-client/flink-conf.yaml
        target: /opt/flink/conf/custom-flink-conf.yaml
      - type: bind
        source: ${PWD}/flink/sql-jobs/clickstream-filtering.sql
        target: /opt/flink/streaming-job.sql
    command: >
      /bin/bash -c "
      /opt/flink/bin/sql-client.sh -f /opt/flink/streaming-job.sql;
      exec /bin/tail -f /dev/null
      "
    networks:
      - stream-lakehouse
  minio-storage-service:
    image: minio/minio:latest
    container_name: object-storage-svc
    environment:
      MINIO_ROOT_USER: minio-admin
      MINIO_ROOT_PASSWORD: minio-password-1
      MINIO_DOMAIN: minio-svc
    networks:
      stream-lakehouse:
        aliases:
          - s3-storage-endpoint
    ports:
      - 9002:9001
      - 9003:9000
    command: ["server", "/data", "--console-address", ":9001"]
  minio-initializer:
    depends_on:
      - minio-storage-service
    image: minio/mc
    container_name: bucket-initializer
    networks:
      - stream-lakehouse
    environment:
      AWS_ACCESS_KEY: minio-admin
      AWS_SECRET_KEY: minio-password-1
      AWS_REGION: us-east-1
      AWS_DEFAULT_REGION_NAME: us-east-1
    entrypoint: >
      /bin/sh -c "
      until (/usr/bin/mc config host add minio-alias http://minio-storage-service:9000 minio-admin minio-password-1) do echo '...waiting for MinIO...' && sleep 1; done;
      /usr/bin/mc rm -r --force minio-alias/data-repo;
      /usr/bin/mc mb minio-alias/data-repo;
      /usr/bin/mc policy set download minio-alias/data-repo;
      exec /usr/bin/tail -f /dev/null
      "
  iceberg-catalog-svc:
    image: tabulario/iceberg-rest
    container_name: iceberg-catalog-svc
    ports:
      - 8182:8181
    environment:
      AWS_ACCESS_KEY: user-s3
      AWS_SECRET_KEY: s3-secret-key
      AWS_REGION_CODE: us-east-1
      CATALOG_WAREHOUSE_ROOT: s3://data-repo/
      CATALOG_S3_IMPL_CLASS: org.apache.iceberg.aws.s3.S3FileIO
      CATALOG_S3_EXTERNAL_ENDPOINT: http://minio-storage-service:9000
    networks:
      - stream-lakehouse
  query-engine:
    image: trinodb/trino:430
    container_name: trino-query-server
    networks:
      - stream-lakehouse
    environment:
      TRINO_USER: analytics_user
      TRINO_PASSWORD: safe-query-pass
    ports:
      - 8889:8080
    depends_on:
      - iceberg-catalog-svc
      - minio-storage-service
    volumes:
      - ./trino/catalog-config.properties:/etc/trino/catalog/iceberg.properties
  visualization-tool:
    build:
      context: ./superset
    container_name: data-visualization-app
    networks:
      - stream-lakehouse
    environment:
      ADMIN_USERNAME: viz_master
      ADMIN_EMAIL: viz@pipeline.com
      ADMIN_PASSWORD: superstrongpassword
    ports:
      - 9099:8088
networks:
  stream-lakehouse:
    driver: bridge
volumes:
  minio_object_data:
  superset_metadata_volume: